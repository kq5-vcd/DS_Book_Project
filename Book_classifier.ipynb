{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from itertools import islice\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KModes:\n",
    "    def __init__(self, distance, frequency_calculator, sample_frequency, get_centroid, k):\n",
    "        self.k = k\n",
    "        self.distance = distance\n",
    "        self.frequency_calculator = frequency_calculator\n",
    "        self.sample_frequency = sample_frequency\n",
    "        self.get_centroid = get_centroid\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.dataset = data.values.tolist()\n",
    "        \n",
    "        # Step 1: Get centroids\n",
    "        self.centroids = []\n",
    "        centroids_old = []\n",
    "\n",
    "        for i in range(self.k):\n",
    "            centroid = random.choice(self.dataset)\n",
    "\n",
    "            while centroid in self.centroids:\n",
    "                centroid = random.choice(self.dataset)\n",
    "\n",
    "            self.centroids.append(centroid)\n",
    "\n",
    "        error = np.ones(self.k)\n",
    "        self.labels = [0 for x in range(len(self.dataset))]\n",
    "\n",
    "        while error.all() != 0:\n",
    "            # Step 2: Distance\n",
    "            # Cluster labels for each point\n",
    "            self.labels = [0 for x in range(len(self.dataset))]\n",
    "\n",
    "            # Distances to each centroid\n",
    "            distances = np.zeros(self.k)\n",
    "\n",
    "            # Frequency for mode\n",
    "            frequency = [deepcopy(self.sample_frequency) for x in range(self.k)]\n",
    "\n",
    "            # Calculate distance to each centroid\n",
    "            for i in range(len(self.dataset)):\n",
    "                cluster = -1\n",
    "                if self.dataset[i] not in self.centroids:\n",
    "                    for j in range(self.k):\n",
    "                        distances[j] = self.distance(self.dataset[i], self.centroids[j])\n",
    "\n",
    "                    cluster = np.argmin(distances)\n",
    "                else:\n",
    "                    cluster = self.centroids.index(self.dataset[i])\n",
    "                    \n",
    "                self.labels[i] = cluster\n",
    "                frequency[cluster] = self.frequency_calculator(self.dataset[i], frequency[cluster]) \n",
    "\n",
    "            # Step 3: Update centroids\n",
    "            centroids_old = deepcopy(self.centroids)\n",
    "\n",
    "            for i in range(self.k):\n",
    "                proposed_centroid = self.get_centroid(frequency[i])\n",
    "                temp_centroid = proposed_centroid\n",
    "                best_distance = 10\n",
    "                \n",
    "                for j in range(len(self.dataset)):\n",
    "                    if self.labels[j] == i:\n",
    "                        current_dist = self.distance(proposed_centroid, self.dataset[j])\n",
    "                        \n",
    "                        if current_dist < best_distance:\n",
    "                            temp_centroid = self.dataset[j]\n",
    "                            best_distance = current_dist\n",
    "                            \n",
    "                self.centroids[i] = temp_centroid\n",
    "\n",
    "                error[i] = self.distance(self.centroids[i], centroids_old[i])\n",
    "\n",
    "    def inertia(self):\n",
    "        total_distance = 0.0\n",
    "\n",
    "        for i in range(self.k):\n",
    "            for j in range(len(self.dataset)):\n",
    "                if self.labels[j] == i:\n",
    "                    total_distance += self.distance(self.centroids[i], self.dataset[j])\n",
    "\n",
    "        return total_distance\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data_list = data.values.tolist()\n",
    "        result = [0 for x in range(len(data))]\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            distances = [0 for x in range(self.k)]\n",
    "            for j in range(self.k):\n",
    "                distances[j] = self.distance(data_list[i], self.centroids[j])\n",
    "\n",
    "            result[i] = np.argmin(distances)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def get_centroids(self):\n",
    "        return self.centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.sample_frequency = {'author': {}, 'series': {}, 'tags': {}, 'length': {}}\n",
    "        self.model = KModes(self.distance, self.get_frequency, self.sample_frequency, self.get_centroid, self.k)\n",
    "        \n",
    "    def individual_distance(self, a, b):\n",
    "        a_lst = a.strip('\\\"').split(', ')\n",
    "        b_lst = b.strip('\\\"').split(', ')\n",
    "\n",
    "        total_length = max(len(a_lst), len(b_lst))\n",
    "        difference = total_length\n",
    "\n",
    "        for ele in a_lst:\n",
    "            if ele in b_lst:\n",
    "                difference -= 1\n",
    "\n",
    "        return 1.0 * difference/total_length\n",
    "\n",
    "\n",
    "    def distance(self, book_1, book_2):\n",
    "        distance = 0.0\n",
    "\n",
    "        distance += self.individual_distance(book_1[0], book_2[0])\n",
    "        distance += self.individual_distance(book_1[2], book_2[2])\n",
    "\n",
    "        if book_1[1] != 'none' and book_1[1] == book_2[1]:\n",
    "            distance += 0.0\n",
    "        else:\n",
    "            distance += 1.0\n",
    "\n",
    "        return distance\n",
    "\n",
    "    def get_frequency(self, book, cluster):\n",
    "        authors = book[0].strip('\\\"').split(', ')\n",
    "\n",
    "        for author in authors:\n",
    "            if author in cluster['author']:\n",
    "                cluster['author'][author] += 1\n",
    "            else:\n",
    "                cluster['author'][author] = 1\n",
    "\n",
    "        if book[1] in cluster['series']:\n",
    "            cluster['series'][book[1]] += 1\n",
    "        else:\n",
    "            cluster['series'][book[1]] = 1\n",
    "\n",
    "        tags = book[2].strip('\\\"').split(', ')\n",
    "\n",
    "        for tag in tags:\n",
    "            if tag in cluster['tags']:\n",
    "                cluster['tags'][tag] += 1\n",
    "        else:\n",
    "            cluster['tags'][tag] = 1\n",
    "\n",
    "        length = len(tags)\n",
    "\n",
    "        if length in cluster['length']:\n",
    "            cluster['length'][length] += 1\n",
    "        else:\n",
    "            cluster['length'][length] = 1\n",
    "\n",
    "        return cluster\n",
    "\n",
    "    def get_centroid(self, cluster):\n",
    "        new_centroid = []\n",
    "\n",
    "        new_centroid.append(max(cluster['author'], key = cluster['author'].get))\n",
    "        new_centroid.append(max(cluster['series'], key = cluster['series'].get))\n",
    "\n",
    "        tag_len = max(cluster['length'], key = cluster['length'].get)\n",
    "\n",
    "        tags_sorted = {k: v for k, v in sorted(cluster['tags'].items(), key=lambda item: item[1])}\n",
    "        tags = [x[0] for x in islice(tags_sorted.items(), 0, tag_len)]\n",
    "\n",
    "        new_centroid += tags\n",
    "\n",
    "        return new_centroid\n",
    "\n",
    "    def fit(self, data, reviews):\n",
    "        clustering = data[['Author', 'Series', 'Tags']]\n",
    "        classification = data[['Raters', 'Reviewers', 'Pages', 'PublishYear']].values.tolist()\n",
    "        review_list = reviews.values.tolist()\n",
    "        \n",
    "        self.model.fit(clustering)\n",
    "        \n",
    "        labels = self.model.get_labels()\n",
    "        \n",
    "        self.clusters = [[] for x in range(self.k)]\n",
    "        self.cluster_labels = [[] for x in range(self.k)]\n",
    "        \n",
    "        for i in range(len(classification)):\n",
    "            self.clusters[labels[i]].append(classification[i])\n",
    "            self.cluster_labels[labels[i]].append(review_list[i])\n",
    "            \n",
    "    def train_classifiers(self, classifier):\n",
    "        classifiers = [deepcopy(classifier) for x in range(self.k)]\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            classifiers[i].fit(self.clusters[i], self.cluster_labels[i])   \n",
    "            \n",
    "        return classifiers\n",
    "            \n",
    "    def predict(self, test, classifier):\n",
    "        classifiers = self.train_classifiers(classifier)\n",
    "        \n",
    "        clustering = test[['Author', 'Series', 'Tags']]\n",
    "        classification = test[['Raters', 'Reviewers', 'Pages', 'PublishYear']].values.tolist()\n",
    "        \n",
    "        labels = self.model.predict(clustering)\n",
    "        \n",
    "        result = [0 for x in range(len(classification))]\n",
    "        \n",
    "        for i in range(len(classification)):\n",
    "            result[i] = classifiers[labels[i]].predict([classification[i]])[0]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, labels):\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        if predict[i] == labels.values.tolist()[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    return correct/len(labels)\n",
    "    \n",
    "def confusion_matrix(k, predict, labels):\n",
    "    result_matrix = np.zeros((k, k), dtype='int32')\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        result_matrix[labels.values.tolist()[i]][predict[i]] += 1\n",
    "        \n",
    "    return result_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Raters</th>\n",
       "      <th>Reviewers</th>\n",
       "      <th>Pages</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>GenreLink</th>\n",
       "      <th>Series</th>\n",
       "      <th>review</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97594</th>\n",
       "      <td>299919</td>\n",
       "      <td>How to Learn a Foreign Language</td>\n",
       "      <td>Graham E. Fuller</td>\n",
       "      <td>3.35</td>\n",
       "      <td>109</td>\n",
       "      <td>18</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>/work/shelves/290993</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>to-read, language, non-fiction, currently-read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97595</th>\n",
       "      <td>299940</td>\n",
       "      <td>It Seemed Important at the Time: A Romance Memoir</td>\n",
       "      <td>Gloria Vanderbilt</td>\n",
       "      <td>3.25</td>\n",
       "      <td>890</td>\n",
       "      <td>78</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>/work/shelves/291014</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>to-read, currently-reading, non-fiction, memoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97596</th>\n",
       "      <td>299941</td>\n",
       "      <td>Once Upon a Time</td>\n",
       "      <td>Gloria Vanderbilt</td>\n",
       "      <td>3.64</td>\n",
       "      <td>240</td>\n",
       "      <td>20</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>/work/shelves/291015</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>to-read, memoir, biography, currently-reading,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97597</th>\n",
       "      <td>299942</td>\n",
       "      <td>A Mother's Story</td>\n",
       "      <td>Gloria Vanderbilt</td>\n",
       "      <td>3.67</td>\n",
       "      <td>247</td>\n",
       "      <td>33</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>/work/shelves/291016</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>to-read, non-fiction, memoir, currently-readin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97598</th>\n",
       "      <td>299934</td>\n",
       "      <td>The Short and Bloody History of Knights, Spies...</td>\n",
       "      <td>John Farman</td>\n",
       "      <td>3.50</td>\n",
       "      <td>101</td>\n",
       "      <td>18</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>/work/shelves/291008</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>to-read, own, non-fiction, history, currently-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97599</th>\n",
       "      <td>299947</td>\n",
       "      <td>X-Men: God Loves, Man Kills</td>\n",
       "      <td>Chris Claremont, Brent Anderson</td>\n",
       "      <td>4.15</td>\n",
       "      <td>18149</td>\n",
       "      <td>442</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>/work/shelves/1410200</td>\n",
       "      <td>Marvel Graphic Novel</td>\n",
       "      <td>2</td>\n",
       "      <td>to-read, comics, graphic-novels, currently-rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97600</th>\n",
       "      <td>299948</td>\n",
       "      <td>X-Treme X-Men, Vol. 5: God Loves, Man Kills</td>\n",
       "      <td>Chris Claremont, Igor Kordey, Salvador Larroca...</td>\n",
       "      <td>3.21</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>/work/shelves/18626296</td>\n",
       "      <td>X-Treme X-Men (2001) (Collected Editions)</td>\n",
       "      <td>1</td>\n",
       "      <td>to-read, comics, x-men, graphic-novels, marvel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97601</th>\n",
       "      <td>299961</td>\n",
       "      <td>Who Moved the Stone?</td>\n",
       "      <td>Frank Morison, Lee Strobel</td>\n",
       "      <td>3.92</td>\n",
       "      <td>623</td>\n",
       "      <td>72</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>/work/shelves/291035</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>to-read, currently-reading, christian, apologe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97602</th>\n",
       "      <td>299960</td>\n",
       "      <td>The Earth Moved: On the Remarkable Achievement...</td>\n",
       "      <td>Amy  Stewart</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2064</td>\n",
       "      <td>369</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>/work/shelves/291034</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>to-read, science, non-fiction, currently-readi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97603</th>\n",
       "      <td>299980</td>\n",
       "      <td>Silent Warfare: Understanding the World of Int...</td>\n",
       "      <td>Abram N. Shulsky, Gary J. Schmitt</td>\n",
       "      <td>3.64</td>\n",
       "      <td>211</td>\n",
       "      <td>9</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>/work/shelves/291054</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>to-read, currently-reading, intelligence, non-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BookID                                              Title  \\\n",
       "97594  299919                    How to Learn a Foreign Language   \n",
       "97595  299940  It Seemed Important at the Time: A Romance Memoir   \n",
       "97596  299941                                   Once Upon a Time   \n",
       "97597  299942                                   A Mother's Story   \n",
       "97598  299934  The Short and Bloody History of Knights, Spies...   \n",
       "97599  299947                        X-Men: God Loves, Man Kills   \n",
       "97600  299948        X-Treme X-Men, Vol. 5: God Loves, Man Kills   \n",
       "97601  299961                               Who Moved the Stone?   \n",
       "97602  299960  The Earth Moved: On the Remarkable Achievement...   \n",
       "97603  299980  Silent Warfare: Understanding the World of Int...   \n",
       "\n",
       "                                                  Author  Rate  Raters  \\\n",
       "97594                                   Graham E. Fuller  3.35     109   \n",
       "97595                                  Gloria Vanderbilt  3.25     890   \n",
       "97596                                  Gloria Vanderbilt  3.64     240   \n",
       "97597                                  Gloria Vanderbilt  3.67     247   \n",
       "97598                                        John Farman  3.50     101   \n",
       "97599                    Chris Claremont, Brent Anderson  4.15   18149   \n",
       "97600  Chris Claremont, Igor Kordey, Salvador Larroca...  3.21     148   \n",
       "97601                         Frank Morison, Lee Strobel  3.92     623   \n",
       "97602                                       Amy  Stewart  3.89    2064   \n",
       "97603                  Abram N. Shulsky, Gary J. Schmitt  3.64     211   \n",
       "\n",
       "       Reviewers  Pages  PublishYear               GenreLink  \\\n",
       "97594         18  102.0         1987    /work/shelves/290993   \n",
       "97595         78  161.0         2004    /work/shelves/291014   \n",
       "97596         20  352.0         1985    /work/shelves/291015   \n",
       "97597         33  160.0         1996    /work/shelves/291016   \n",
       "97598         18  287.0         2003    /work/shelves/291008   \n",
       "97599        442   64.0         1982   /work/shelves/1410200   \n",
       "97600          8  216.0         2003  /work/shelves/18626296   \n",
       "97601         72  193.0         1930    /work/shelves/291035   \n",
       "97602        369  240.0         2004    /work/shelves/291034   \n",
       "97603          9  262.0         1991    /work/shelves/291054   \n",
       "\n",
       "                                          Series  review  \\\n",
       "97594                                       none       1   \n",
       "97595                                       none       1   \n",
       "97596                                       none       1   \n",
       "97597                                       none       1   \n",
       "97598                                       none       1   \n",
       "97599                       Marvel Graphic Novel       2   \n",
       "97600  X-Treme X-Men (2001) (Collected Editions)       1   \n",
       "97601                                       none       2   \n",
       "97602                                       none       2   \n",
       "97603                                       none       1   \n",
       "\n",
       "                                                    Tags  \n",
       "97594  to-read, language, non-fiction, currently-read...  \n",
       "97595  to-read, currently-reading, non-fiction, memoi...  \n",
       "97596  to-read, memoir, biography, currently-reading,...  \n",
       "97597  to-read, non-fiction, memoir, currently-readin...  \n",
       "97598  to-read, own, non-fiction, history, currently-...  \n",
       "97599  to-read, comics, graphic-novels, currently-rea...  \n",
       "97600  to-read, comics, x-men, graphic-novels, marvel...  \n",
       "97601  to-read, currently-reading, christian, apologe...  \n",
       "97602  to-read, science, non-fiction, currently-readi...  \n",
       "97603  to-read, currently-reading, intelligence, non-...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/complete_data.csv')\n",
    "\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Raters</th>\n",
       "      <th>Reviewers</th>\n",
       "      <th>Pages</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>Series</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97599</th>\n",
       "      <td>Chris Claremont, Brent Anderson</td>\n",
       "      <td>18149</td>\n",
       "      <td>442</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>Marvel Graphic Novel</td>\n",
       "      <td>to-read, comics, graphic-novels, currently-rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97600</th>\n",
       "      <td>Chris Claremont, Igor Kordey, Salvador Larroca...</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>X-Treme X-Men (2001) (Collected Editions)</td>\n",
       "      <td>to-read, comics, x-men, graphic-novels, marvel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97601</th>\n",
       "      <td>Frank Morison, Lee Strobel</td>\n",
       "      <td>623</td>\n",
       "      <td>72</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>none</td>\n",
       "      <td>to-read, currently-reading, christian, apologe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97602</th>\n",
       "      <td>Amy  Stewart</td>\n",
       "      <td>2064</td>\n",
       "      <td>369</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>none</td>\n",
       "      <td>to-read, science, non-fiction, currently-readi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97603</th>\n",
       "      <td>Abram N. Shulsky, Gary J. Schmitt</td>\n",
       "      <td>211</td>\n",
       "      <td>9</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>none</td>\n",
       "      <td>to-read, currently-reading, intelligence, non-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Author  Raters  Reviewers  \\\n",
       "97599                    Chris Claremont, Brent Anderson   18149        442   \n",
       "97600  Chris Claremont, Igor Kordey, Salvador Larroca...     148          8   \n",
       "97601                         Frank Morison, Lee Strobel     623         72   \n",
       "97602                                       Amy  Stewart    2064        369   \n",
       "97603                  Abram N. Shulsky, Gary J. Schmitt     211          9   \n",
       "\n",
       "       Pages  PublishYear                                     Series  \\\n",
       "97599   64.0         1982                       Marvel Graphic Novel   \n",
       "97600  216.0         2003  X-Treme X-Men (2001) (Collected Editions)   \n",
       "97601  193.0         1930                                       none   \n",
       "97602  240.0         2004                                       none   \n",
       "97603  262.0         1991                                       none   \n",
       "\n",
       "                                                    Tags  \n",
       "97599  to-read, comics, graphic-novels, currently-rea...  \n",
       "97600  to-read, comics, x-men, graphic-novels, marvel...  \n",
       "97601  to-read, currently-reading, christian, apologe...  \n",
       "97602  to-read, science, non-fiction, currently-readi...  \n",
       "97603  to-read, currently-reading, intelligence, non-...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = data[['Author', 'Raters', 'Reviewers', 'Pages', 'PublishYear', 'Series', 'Tags']]\n",
    "labels = data['review']\n",
    "\n",
    "info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97599    2\n",
       "97600    1\n",
       "97601    2\n",
       "97602    2\n",
       "97603    1\n",
       "Name: review, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78083 19521\n"
     ]
    }
   ],
   "source": [
    "info_train, info_test, labels_train, labels_test = train_test_split(info, labels, train_size = 0.8, test_size = 0.2, random_state=42)\n",
    "\n",
    "print(len(info_train), len(info_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_classifier = BookClassifier(3)\n",
    "book_classifier.fit(info_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors = 11)\n",
    "\n",
    "main_predict = book_classifier.predict(info_test, knn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier.fit(info_train[['Raters', 'Reviewers', 'Pages', 'PublishYear']], labels_train)\n",
    "\n",
    "knn_predict = knn_classifier.predict(info_test[['Raters', 'Reviewers', 'Pages', 'PublishYear']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6721991701244814"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(main_predict, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6707135904922904"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(knn_predict, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,   170,   104],\n",
       "       [    6,  2373,  3470],\n",
       "       [    0,  2649, 10749]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(3, main_predict, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,   125,   148],\n",
       "       [    1,  1482,  4366],\n",
       "       [    2,  1786, 11610]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(3, knn_predict, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier_2 = KNeighborsClassifier(n_neighbors = 37)\n",
    "\n",
    "main_predict_2 = book_classifier.predict(info_test, knn_classifier_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier_2.fit(info_train[['Raters', 'Reviewers', 'Pages', 'PublishYear']], labels_train)\n",
    "\n",
    "knn_predict_2 = knn_classifier_2.predict(info_test[['Raters', 'Reviewers', 'Pages', 'PublishYear']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6891040418011373 0.6873111008657343\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(main_predict_2, labels_test), accuracy(knn_predict_2, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   172   102]\n",
      " [    0  2100  3749]\n",
      " [    0  2046 11352]]\n",
      "[[    0   109   165]\n",
      " [    0   975  4874]\n",
      " [    0   956 12442]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(3, main_predict_2, labels_test))\n",
    "print(confusion_matrix(3, knn_predict_2, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "main_predict_3 = book_classifier.predict(info_test, nb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(info_train[['Raters', 'Reviewers', 'Pages', 'PublishYear']], labels_train)\n",
    "nb_predict = nb_classifier.predict(info_test[['Raters', 'Reviewers', 'Pages', 'PublishYear']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2909687003739563 0.1564981302187388\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(main_predict_3, labels_test), accuracy(nb_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 137  126   11]\n",
      " [2501 2823  525]\n",
      " [4560 6118 2720]]\n",
      "[[ 241   26    7]\n",
      " [4492 1019  338]\n",
      " [8279 3324 1795]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(3, main_predict_3, labels_test))\n",
    "print(confusion_matrix(3, nb_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state = 42, max_depth = 4)\n",
    "main_predict_4 = book_classifier.predict(info_test, dt_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.fit(info_train[['Raters', 'Reviewers', 'Pages', 'PublishYear']], labels_train)\n",
    "dt_predict = dt_classifier.predict(info_test[['Raters', 'Reviewers', 'Pages', 'PublishYear']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915629322268326 0.6862353363044926\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(main_predict_4, labels_test), accuracy(dt_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   126   148]\n",
      " [    0  1423  4426]\n",
      " [    0  1321 12077]]\n",
      "[[    0     0   274]\n",
      " [    0     0  5849]\n",
      " [    0     2 13396]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(3, main_predict_4, labels_test))\n",
    "print(confusion_matrix(3, dt_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_classifier_2 = BookClassifier(30)\n",
    "book_classifier_2.fit(info_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_predict_2_1 = book_classifier_2.predict(info_test, knn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685723067465806 0.6707135904922904\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(main_predict_2_1, labels_test), accuracy(knn_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   122   152]\n",
      " [    5  1897  3947]\n",
      " [    3  1906 11489]]\n",
      "[[    1   125   148]\n",
      " [    1  1482  4366]\n",
      " [    2  1786 11610]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(3, main_predict_2_1, labels_test))\n",
    "print(confusion_matrix(3, knn_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_predict_2_2 = book_classifier_2.predict(info_test, knn_classifier_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7045745607294708 0.6873111008657343\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(main_predict_2_2, labels_test), accuracy(knn_predict_2, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   122   152]\n",
      " [    5  1897  3947]\n",
      " [    3  1906 11489]]\n",
      "[[    1   125   148]\n",
      " [    1  1482  4366]\n",
      " [    2  1786 11610]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(3, main_predict_2_1, labels_test))\n",
    "print(confusion_matrix(3, knn_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_predict_2_3 = book_classifier_2.predict(info_test, nb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35305568362276524 0.1564981302187388\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(main_predict_2_3, labels_test), accuracy(nb_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121  135   18]\n",
      " [2219 2663  967]\n",
      " [4399 4891 4108]]\n",
      "[[ 241   26    7]\n",
      " [4492 1019  338]\n",
      " [8279 3324 1795]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(3, main_predict_2_3, labels_test))\n",
    "print(confusion_matrix(3, nb_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_predict_2_4 = book_classifier_2.predict(info_test, dt_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6996055529942113 0.6862353363044926\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(main_predict_2_4, labels_test), accuracy(dt_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   108   166]\n",
      " [    2  1487  4360]\n",
      " [    1  1227 12170]]\n",
      "[[    0     0   274]\n",
      " [    0     0  5849]\n",
      " [    0     2 13396]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(3, main_predict_2_4, labels_test))\n",
    "print(confusion_matrix(3, dt_predict, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
